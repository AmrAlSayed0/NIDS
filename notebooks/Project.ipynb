{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Acquire the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data set\n",
    "df = pd.read_csv ( '../data/kddcup.data.corrected' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the first few rows, make sure data is loaded correctly. The number of columns (features) is as expected\n",
    "df.head ( 10 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inspect the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the data type of each feature. Maybe convert them to more appropriate data type later.\n",
    "num_of_data_points = df.shape [ 0 ]\n",
    "num_of_features = df.shape [ 1 ]\n",
    "df.info ( verbose = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like there are data that are misrepresented as 'object' or 'int64' when they're in fact category strings or booleans\n",
    "# Here we fix that\n",
    "df [ 'protocol_type' ] = df [ 'protocol_type' ].astype ( 'category' )\n",
    "df [ 'service' ] = df [ 'service' ].astype ( 'category' )\n",
    "df [ 'flag' ] = df [ 'flag' ].astype ( 'category' )\n",
    "df [ 'land' ] = df [ 'land' ].astype ( 'category' )\n",
    "df [ 'logged_in' ] = df [ 'logged_in' ].astype ( 'category' )\n",
    "df [ 'is_host_login' ] = df [ 'is_host_login' ].astype ( 'category' )\n",
    "df [ 'is_guest_login' ] = df [ 'is_guest_login' ].astype ( 'category' )\n",
    "df [ 'target' ] = df [ 'target' ].astype ( 'category' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look and check the conversion is correct\n",
    "df.info ( verbose = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the data for any unusual or invalid values (e.g negative values for duration or byte size or count and values above 1 for rate)\n",
    "df.describe ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick scan for categorical columns\n",
    "df.describe ( include = 'category' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cleanup the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any nan or invalid values. Remove them if there is.\n",
    "df [ df.isna ().any ( axis = 1 ) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Standarize/Categorize Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df [ 'protocol_type' ].unique ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df [ 'service' ].unique ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df [ 'flag' ].unique ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df [ 'land' ].unique ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df [ 'logged_in' ].unique ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df [ 'is_host_login' ].unique ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df [ 'is_guest_login' ].unique ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df [ 'target' ].unique ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze Variables (Reduce Dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, it was notied that the feature named 'num_outbound_cmds' is nothing but zero values.\n",
    "df [ 'num_outbound_cmds' ].describe ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we drop it\n",
    "df = df.drop ( columns = [ 'num_outbound_cmds' ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have a total of 34 numerical/continuous features and 7 categorical features\n",
    "# We define feature selection methods\n",
    "x_numerical = df.select_dtypes ( exclude = [ object , 'category' ] )\n",
    "# Let's say we only need a set percentage of the total number of features\n",
    "percentage_of_features = 0.5\n",
    "num_of_numerical_features = x_numerical.shape [ 1 ]\n",
    "num_of_selected_numerical_features = math.ceil ( num_of_numerical_features * percentage_of_features )\n",
    "# Here we use Analysis Of Variance (AVONA) F-Test. It is best suited for numerical input and categorical output.\n",
    "fs = SelectKBest ( score_func = f_classif , k = num_of_selected_numerical_features )\n",
    "# Apply the feature selection\n",
    "y = df [ 'target' ]\n",
    "x_numerical_selected = fs.fit_transform ( x_numerical , y )\n",
    "x_numerical.loc [ : , fs.get_support ( indices = False ) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "corr = df.select_dtypes ( exclude = [ object , 'category' ] ).corr (method='pearson')\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu ( np.ones_like ( corr , dtype = bool ) )\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f , ax = plt.subplots ( figsize = (20 , 20) )\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette ( 240 , 360 , as_cmap = True )\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap ( corr , mask = mask , cmap = cmap , vmax = .3 , center = 0 , square = True , linewidths = .5 , cbar_kws = {\n",
    "    \"shrink\" : .5\n",
    "    } )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Split the Dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (NIDS)",
   "language": "python",
   "name": "pycharm-817467c4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}